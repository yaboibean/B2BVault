# Run the B2B scraper with preview
python3 B2Bscraper.py

# Debug commands if needed:
# python3 -c "from B2Bscraper import B2BVaultAgent; agent = B2BVaultAgent(); articles = agent.navigate_to_sales_tab_and_get_articles(preview=True); print(f'Found {len(articles)} articles')"

# Check scraped data folder:
# ls -la scraped_data/

# OPEN THE WEBSITE DASHBOARD:
# Start the website server (easiest method):
python3 start_website.py

# Alternative - Start from website directory:
cd scraped_data/website
python3 start_server.py

# Alternative - Quick Python server:
cd scraped_data/website
python3 -m http.server 8000

# Then open in browser:
# http://localhost:8000





UPLOAD:

git init
echo ".DS_Store" >> .gitignore
echo "node_modules/" >> .gitignore
echo "__pycache__/" >> .gitignore
git add .gitignore
git commit -m "Add .gitignore"
git add .
git commit -m "Initial commit: add all project files"
git remote add origin https://github.com/your-username/your-repo-name.git
git pull origin main --rebase
git push --set-upstream origin main








------------------------------------------------------




# 1. Initialize Git (only once per project)
git init

# 2. Create a .gitignore to exclude unwanted files
echo ".DS_Store" >> .gitignore
echo "node_modules/" >> .gitignore
echo "__pycache__/" >> .gitignore
git add .gitignore
git commit -m "Add .gitignore"

# 3. Stage all files
git add .

# 4. Commit with a message
git commit -m "Initial commit: add all project files"

# 5. Link to GitHub remote (replace URL with your own repo)
git remote add origin https://github.com/your-username/your-repo-name.git

# 6. Pull remote changes first if the GitHub repo already has files (e.g., README)
git pull origin main --rebase

# 7. Push to GitHub
git push --set-upstream origin main

